# AWS Bedrock Cost Control Guide

## ⚠️ CRITICAL BILLING CONSIDERATIONS

### How Bedrock Charges You:
1. **Input Tokens**: You pay per token sent TO the model
2. **Output Tokens**: You pay per token generated BY the model
3. **Model-Specific Pricing**: Different models cost different amounts

### Cost-Effective Models for Practice (as of 2024):
- **Claude 3 Haiku**: ~$0.25 per 1M input tokens, ~$1.25 per 1M output tokens
- **Titan Text Lite**: ~$0.10 per 1M input tokens, ~$0.30 per 1M output tokens
- **Llama 2 70B**: ~$0.00065 per 1K input tokens, ~$0.00065 per 1K output tokens

### ⚠️ EXPENSIVE MODELS TO AVOID FOR PRACTICE:
- **Claude 3 Opus**: ~$15 per 1M input tokens, ~$75 per 1M output tokens
- **Claude 3 Sonnet**: ~$3 per 1M input tokens, ~$15 per 1M output tokens

## Cost Protection Strategies Implemented:

### 1. **Input Validation**
   - Maximum input length limit (e.g., 1000 characters)
   - Reject requests that are too large

### 2. **Max Tokens Limit**
   - Always set `max_tokens` in your Bedrock calls
   - Default: 512 tokens (prevent runaway generation)
   - For testing: Use 100-256 tokens

### 3. **Use Cheaper Models**
   - Default to Claude Haiku or Titan Text Lite for practice
   - Only use expensive models if explicitly needed

### 4. **Monitor Usage**
   - Enable CloudWatch logging
   - Set up billing alerts in AWS Billing Console
   - Track token usage in responses

### 5. **Environment-Based Controls**
   - Use environment variables to control model selection
   - Easy to switch between dev (cheap) and prod models

## Quick Cost Estimate:
- **1,000 input tokens** ≈ 750 words
- **1,000 output tokens** ≈ 750 words
- Example: Claude Haiku with 1000 input + 500 output tokens ≈ **$0.000875** (~0.09 cents)

## Safety Settings:
✅ Always set `max_tokens` to limit costs  
✅ Validate input length before calling Bedrock  
✅ Use cost-effective models for development  
✅ Monitor CloudWatch metrics  
✅ Set up AWS Billing Alerts ($5, $10, $50 thresholds)

## For AWS Gameday:
- Practice with short prompts (< 500 characters)
- Use max_tokens = 256 for testing
- Stick to Haiku or Titan models
- Monitor your usage during the event

